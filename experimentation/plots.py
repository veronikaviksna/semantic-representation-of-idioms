# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q8lsP_ugkYr9VZ2HP8zjaGOgQRa-KLIC
"""

# -*- coding: utf-8 -*-

import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List


# ============================================================
# Experiment 1: Monolingual analysis (MAGPIE)
# ============================================================

def plot_similarity_distributions(
    sim_fig: np.ndarray,
    sim_lit: np.ndarray,
    sim_cross: np.ndarray,
    bins: int = 50,
):
    """
    Plot cosine similarity distributions for:
    - figurative–figurative
    - literal–literal
    - figurative–literal
    """

    plt.figure(figsize=(7, 5))

    plt.hist(sim_fig, bins=bins, alpha=0.6, label="Figurative–Figurative")
    plt.hist(sim_lit, bins=bins, alpha=0.6, label="Literal–Literal")
    plt.hist(sim_cross, bins=bins, alpha=0.6, label="Figurative–Literal")

    plt.xlabel("Cosine similarity")
    plt.ylabel("Frequency")
    plt.title("Similarity distributions (MAGPIE)")
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_precision_at_k(
    precision_at_k: Dict[int, float]
):
    """
    Plot Precision@k curve for neighborhood cohesion.
    """

    ks = sorted(precision_at_k.keys())
    values = [precision_at_k[k] for k in ks]

    plt.figure(figsize=(6, 4))
    plt.plot(ks, values, marker="o")

    plt.xlabel("k")
    plt.ylabel("Precision@k")
    plt.title("Neighborhood cohesion (Precision@k)")
    plt.ylim(0, 1.05)
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_pca(
    X_proj: np.ndarray,
    labels: np.ndarray,
    title: str = "PCA projection",
):
    """
    Scatter plot for PCA projection with usage labels.
    """

    if len(X_proj) != len(labels):
        raise ValueError(
            f"Shape mismatch: X_proj has {len(X_proj)} rows, "
            f"labels has {len(labels)} entries"
        )

    plt.figure(figsize=(6, 6))

    for label in np.unique(labels):
        idx = labels == label
        plt.scatter(
            X_proj[idx, 0],
            X_proj[idx, 1],
            s=10,
            alpha=0.6,
            label=label,
        )

    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.title(title)
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


# ============================================================
# Experiment 2: Cross-lingual alignment (IdiomsInContext-MT)
# ============================================================

def plot_aligned_vs_random(
    aligned: np.ndarray,
    random: np.ndarray,
    bins: int = 50,
    title: str = "Aligned vs random similarity",
):
    """
    Histogram comparing aligned and random cross-lingual similarities.
    """

    plt.figure(figsize=(7, 5))

    plt.hist(aligned, bins=bins, alpha=0.7, label="Aligned RU–EN")
    plt.hist(random, bins=bins, alpha=0.7, label="Random RU–EN")

    plt.xlabel("Cosine similarity")
    plt.ylabel("Frequency")
    plt.title(title)
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_difference_histogram(
    aligned: np.ndarray,
    random: np.ndarray,
    bins: int = 50,
):
    """
    Histogram of similarity differences: aligned − random.
    """

    diff = aligned - random

    plt.figure(figsize=(7, 5))
    plt.hist(diff, bins=bins, alpha=0.8)

    plt.axvline(0, linestyle="--")
    plt.xlabel("Cosine similarity difference")
    plt.ylabel("Frequency")
    plt.title("Difference: aligned − random")
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_pca_crosslingual(
    X_proj: np.ndarray,
    lang_labels: List[str],
    title: str = "Cross-lingual PCA",
):
    """
    PCA plot for RU + EN embeddings together.
    """

    if len(X_proj) != len(lang_labels):
        raise ValueError(
            f"Shape mismatch: X_proj has {len(X_proj)} rows, "
            f"lang_labels has {len(lang_labels)} entries"
        )

    plt.figure(figsize=(6, 6))

    for lang in sorted(set(lang_labels)):
        idx = np.array(lang_labels) == lang
        plt.scatter(
            X_proj[idx, 0],
            X_proj[idx, 1],
            s=12,
            alpha=0.6,
            label=lang,
        )

    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.title(title)
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


# ============================================================
# Experiment 3: Semantic vs Lexical preference (LIdioms)
# ============================================================

def plot_literal_vs_idiomatic_difference(
    diff: np.ndarray,
    bins: int = 30,
    title: str = "Literal vs Idiomatic similarity difference",
):
    """
    Histogram of similarity differences:
    cos(RU, literal) − cos(RU, idiomatic)
    """

    plt.figure(figsize=(6, 4))
    plt.hist(diff, bins=bins, alpha=0.8)

    plt.axvline(0, linestyle="--")
    plt.xlabel("Cosine similarity difference")
    plt.ylabel("Frequency")
    plt.title(title)
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_pairwise_similarity_scatter(
    sim_idiomatic: np.ndarray,
    sim_literal: np.ndarray,
    title: str = "Pairwise similarity: idiomatic vs literal",
):
    """
    Scatter plot comparing RU–idiomatic vs RU–literal similarities.
    """

    plt.figure(figsize=(5, 5))
    plt.scatter(sim_idiomatic, sim_literal, alpha=0.6)

    lims = [
        min(sim_idiomatic.min(), sim_literal.min()),
        max(sim_idiomatic.max(), sim_literal.max()),
    ]
    plt.plot(lims, lims, linestyle="--")

    plt.xlabel("cos(RU, idiomatic)")
    plt.ylabel("cos(RU, literal)")
    plt.title(title)
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()